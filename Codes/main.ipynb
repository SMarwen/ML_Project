{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal # Signal Processing Library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd # DataBase management\n",
    "import seaborn # Improve Images\n",
    "from statsmodels.tsa.ar_model import AR, ARResults\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>label</th>\n",
       "      <th>label_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>2215</td>\n",
       "      <td>2153</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1667</td>\n",
       "      <td>2072</td>\n",
       "      <td>2047</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1611</td>\n",
       "      <td>1957</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1601</td>\n",
       "      <td>1939</td>\n",
       "      <td>1831</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1643</td>\n",
       "      <td>1965</td>\n",
       "      <td>1879</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ax    ay    az  label            label_str\n",
       "0  1502  2215  2153      1  Working at Computer\n",
       "1  1667  2072  2047      1  Working at Computer\n",
       "2  1611  1957  1906      1  Working at Computer\n",
       "3  1601  1939  1831      1  Working at Computer\n",
       "4  1643  1965  1879      1  Working at Computer"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Column Names ##\n",
    "nm = ['ind', 'ax', 'ay', 'az', 'label'] # Names of columns\n",
    "acc_nm = ['ax', 'ay', 'az'] # Names of signal features\n",
    "## Load Dataset\n",
    "link = \"Dataset/1.csv\"\n",
    "def loadDB(link):\n",
    "    \"A function that import the database from Dataset folder and return df\"\n",
    "    \n",
    "    label2str = {1:'Working at Computer', 2:'Standing Up, Walking and Going up-down stairs', \n",
    "                 3:'Standing', 4:'Walking',5:'Going Up\\Down Stairs', 6:'Walking and Talking with Someone', \n",
    "                 7:'Talking while Standing'}\n",
    "    df = pd.read_csv(link, sep=',', names=nm)\n",
    "    del df['ind']\n",
    "    df = df[df.label != 0] # Unusable row\n",
    "    df['label_str'] = df.label.apply(lambda x:label2str[x]) # Important to some plots\n",
    "    return df\n",
    "\n",
    "df_raw = loadDB(link)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>label</th>\n",
       "      <th>label_str</th>\n",
       "      <th>mag</th>\n",
       "      <th>ax_median</th>\n",
       "      <th>ay_median</th>\n",
       "      <th>az_median</th>\n",
       "      <th>ax_diff</th>\n",
       "      <th>ay_diff</th>\n",
       "      <th>az_diff</th>\n",
       "      <th>ax_low-p</th>\n",
       "      <th>ay_low-p</th>\n",
       "      <th>az_low-p</th>\n",
       "      <th>ax_high-p</th>\n",
       "      <th>ay_high-p</th>\n",
       "      <th>az_high-p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1502</td>\n",
       "      <td>2215</td>\n",
       "      <td>2153</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "      <td>3434.768988</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>2072.0</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>0.294570</td>\n",
       "      <td>0.434402</td>\n",
       "      <td>0.422243</td>\n",
       "      <td>1330.950456</td>\n",
       "      <td>1962.753168</td>\n",
       "      <td>1907.813802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1667</td>\n",
       "      <td>2072</td>\n",
       "      <td>2047</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "      <td>3355.932359</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>2072.0</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-143.0</td>\n",
       "      <td>-106.0</td>\n",
       "      <td>2.023204</td>\n",
       "      <td>2.907854</td>\n",
       "      <td>2.832932</td>\n",
       "      <td>1155.714581</td>\n",
       "      <td>1362.002403</td>\n",
       "      <td>1353.118154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1611</td>\n",
       "      <td>1957</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "      <td>3171.435952</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>7.011663</td>\n",
       "      <td>9.821684</td>\n",
       "      <td>9.584772</td>\n",
       "      <td>789.314495</td>\n",
       "      <td>875.625099</td>\n",
       "      <td>847.401747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1601</td>\n",
       "      <td>1939</td>\n",
       "      <td>1831</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "      <td>3110.543843</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>16.960462</td>\n",
       "      <td>23.217970</td>\n",
       "      <td>22.667546</td>\n",
       "      <td>517.382527</td>\n",
       "      <td>551.056967</td>\n",
       "      <td>481.033069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1643</td>\n",
       "      <td>1965</td>\n",
       "      <td>1879</td>\n",
       "      <td>1</td>\n",
       "      <td>Working at Computer</td>\n",
       "      <td>3176.683018</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.066246</td>\n",
       "      <td>44.414894</td>\n",
       "      <td>43.325413</td>\n",
       "      <td>330.972495</td>\n",
       "      <td>313.877533</td>\n",
       "      <td>283.050573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ax    ay    az  label            label_str          mag  ax_median  \\\n",
       "0  1502  2215  2153      1  Working at Computer  3434.768988     1502.0   \n",
       "1  1667  2072  2047      1  Working at Computer  3355.932359     1611.0   \n",
       "2  1611  1957  1906      1  Working at Computer  3171.435952     1611.0   \n",
       "3  1601  1939  1831      1  Working at Computer  3110.543843     1611.0   \n",
       "4  1643  1965  1879      1  Working at Computer  3176.683018     1604.0   \n",
       "\n",
       "   ay_median  az_median  ax_diff  ay_diff  az_diff   ax_low-p   ay_low-p  \\\n",
       "0     2072.0     2047.0    165.0   -143.0   -106.0   0.294570   0.434402   \n",
       "1     2072.0     2047.0    165.0   -143.0   -106.0   2.023204   2.907854   \n",
       "2     1957.0     1906.0    -56.0   -115.0   -141.0   7.011663   9.821684   \n",
       "3     1957.0     1879.0    -10.0    -18.0    -75.0  16.960462  23.217970   \n",
       "4     1959.0     1879.0     42.0     26.0     48.0  33.066246  44.414894   \n",
       "\n",
       "    az_low-p    ax_high-p    ay_high-p    az_high-p  \n",
       "0   0.422243  1330.950456  1962.753168  1907.813802  \n",
       "1   2.832932  1155.714581  1362.002403  1353.118154  \n",
       "2   9.584772   789.314495   875.625099   847.401747  \n",
       "3  22.667546   517.382527   551.056967   481.033069  \n",
       "4  43.325413   330.972495   313.877533   283.050573  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def widen_signal(df):\n",
    "    # Magnitude\n",
    "    df['mag'] = np.sqrt(np.square(df[acc_nm]).sum(axis=1)) \n",
    "    # Median filter - 3rd ordre\n",
    "    def med_fil(df, names):\n",
    "        \"\"\"Filter the signal by a median filter\"\"\"\n",
    "        df_r = pd.DataFrame()\n",
    "        df = df[names]\n",
    "        for column in df.columns:\n",
    "            name = column+'_median'\n",
    "            df_r[name] = signal.medfilt(df[column].values)\n",
    "        return df_r\n",
    "    df_med = med_fil(df, acc_nm)\n",
    "    # Diffrential\n",
    "    def diffrential(df, names):\n",
    "        \"\"\"Compute the differentials of acceleration - Jerk\"\"\"\n",
    "        df = df[names]\n",
    "        df_r = df.diff(periods=1, axis=0).fillna(method='backfill')\n",
    "        df_r.columns = [names[0]+'_diff', names[1]+'_diff', names[2]+'_diff']\n",
    "        return df_r\n",
    "    df_diff = diffrential(df, acc_nm)\n",
    "    # Low pass filter\n",
    "    def lowpass(df, names):\n",
    "        \"\"\"Compute low-pass filter\"\"\"\n",
    "        df = df[names]\n",
    "        df_r = pd.DataFrame()\n",
    "        fs = 52 # frequence sampling is 52\n",
    "        f_cut = 1 # cutoff frequency\n",
    "        fs_n = f_cut*2.0/fs # normalized frequency\n",
    "        b,a = signal.butter(N=3, Wn=fs_n, btype='low')\n",
    "        for column in df.columns : \n",
    "            name = column+'_low-p'\n",
    "            df_r[name] = signal.lfilter(b,a,df[column].values)\n",
    "        return df_r\n",
    "    df_lp = lowpass(df, acc_nm)  \n",
    "    # High pass filter \n",
    "    def highpass(df, names):\n",
    "        \"\"\"Compute high-pass filter\"\"\"\n",
    "        df = df[names]\n",
    "        df_r = pd.DataFrame()\n",
    "        fs = 52 # frequence sampling is 52\n",
    "        f_cut = 1 # cutoff frequency\n",
    "        fs_n = f_cut*2.0/fs # normalized frequency\n",
    "        b,a = signal.butter(N=3, Wn=fs_n, btype='high')\n",
    "        for column in df.columns : \n",
    "            name = column+'_high-p'\n",
    "            df_r[name] = signal.lfilter(b,a,df[column].values)\n",
    "        return df_r\n",
    "    df_hp = highpass(df, acc_nm)\n",
    "\n",
    "    # Compute the total Total\n",
    "    df = pd.concat([df, df_med, df_diff, df_lp, df_hp], axis=1)\n",
    "    return df\n",
    "df_widen = widen_signal(df_raw)\n",
    "df_widen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6249, 144)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def windowing(signal,size,step):\n",
    "    \"\"\"Compute the window\"\"\"\n",
    "    d = len(signal) #length of the signal\n",
    "    nk = int(np.floor((d-size+1)/step))+1 #le nombre de fenetres\n",
    "    wk = np.zeros((nk,size)) #windows\n",
    "    for j in range(nk):\n",
    "        wk[j,:] = signal[j*step:j*step+size]\n",
    "    return wk\n",
    "def window_labels(labels,size,step):\n",
    "    \"\"\"Compute the label of the window\"\"\"\n",
    "    d = len(labels) #length of the signal\n",
    "    nk = int(np.floor((d-size+1)/step))+1 #le nombre de fenetres\n",
    "    labelwk = np.zeros((nk)) #window labels\n",
    "    for j in range(nk):\n",
    "        labelwk[j] = np.max(np.argmax(np.bincount(labels[j*step:j*step+size])))\n",
    "    return labelwk\n",
    "def extract_windows(df,size,step):\n",
    "    \"\"\"\n",
    "    extract windows with the specified size and step from the dataframe df\n",
    "    \n",
    "    Returns:\n",
    "    L : List of dataframes. Each dataframe contains a window extracted from each signal in df.\n",
    "    labels: labels of windows\n",
    "    \"\"\"\n",
    "    \n",
    "    L = []\n",
    "    n = df.shape[0]\n",
    "    L_windows = dict()\n",
    "    n_windows = int(np.floor((n-size+1)/step))+1\n",
    "    for column in df.columns:\n",
    "        if column not in ['label','label_str']:\n",
    "            L_windows[column] = windowing(df[column],size,step)\n",
    "    for i in range(n_windows):\n",
    "        ddf = pd.DataFrame()\n",
    "        for column in df.columns:\n",
    "            if column not in ['label','label_str']:\n",
    "                ddf[column] = L_windows[column][i,:]\n",
    "        L.append(ddf)\n",
    "    labels = window_labels(df['label'],size,step)\n",
    "    return L,labels\n",
    "\n",
    "\n",
    "\n",
    "def compute_features(df):\n",
    "    \"\"\"Compute features from a give dataframe\"\"\"\n",
    "    ## Basic Statistics\n",
    "    m = df.mean(axis=0).values # Mean\n",
    "    ma = df.mad(axis=0).values # Median\n",
    "    std = df.std(axis=0).values # Standard Deviation\n",
    "    var = df.var(axis=0).values # Variance\n",
    "    minimum = df.min(axis=0).values # Minimum\n",
    "    maximum = df.max(axis=0).values # Maximum\n",
    "    skew = df.skew(axis=0).values # Skewness\n",
    "    kurt = df.kurtosis(axis=0).values # Kurtosis\n",
    "    inteQ = (df.quantile(q=0.75, axis=0).values - df.quantile(q=0.25, axis=0).values) # Interquantile\n",
    "    r = np.hstack([m, ma, std, var, minimum, maximum, skew, kurt, inteQ]) # Compute vector of features\n",
    "    return r\n",
    "\n",
    "\n",
    "def compute_matrix_data(df, N_samples=52, percentage=0.5):\n",
    "    \"\"\"Extract Matrix of data\"\"\"\n",
    "    df_X, df_Y = extract_windows(df,N_samples,int(percentage*N_samples))\n",
    "    X = compute_features(df_X[0])\n",
    "    for i in range(1,len(df_X)):\n",
    "        vec = compute_features(df_X[i])\n",
    "        X = np.vstack([X,vec])\n",
    "    \n",
    "    y = np.array(df_Y) # Compute the vector of labels\n",
    "    return X, y\n",
    "\n",
    "X, y = compute_matrix_data(df_widen) # Compute matrix of data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Methods\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier # Ensemble\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression # Logistic Regression\n",
    "## Utils\n",
    "from sklearn.model_selection import GridSearchCV # Choose parameters\n",
    "from sklearn.preprocessing import scale # Normalise matrix\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y\n",
    "X_train_da, y_train = shuffle(X_train, y_train, random_state=0) # Shuffle data\n",
    "X_train = scale(X_train_da) # Scale the data for the classical algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :0.884134615385\n",
      "Confusion Matrix : Logistic Reegression\n",
      "[[1276    0    0    2    1    0   16]\n",
      " [   2    0    0    8    4    3   18]\n",
      " [   0    0    0   20    6    6  398]\n",
      " [   0    0    0 1010    1    6   16]\n",
      " [   1    0    0    3  103    1   15]\n",
      " [   0    0    0   33    2   60   17]\n",
      " [  57    0    0    1    0    0 3163]]\n",
      "SVM :0.897743638982\n",
      "Confusion Matrix : SVM\n",
      "[[1294    0    0    0    0    0    1]\n",
      " [   0   29    0    0    0    0    6]\n",
      " [   0    0   84    4    0    0  342]\n",
      " [   0    0    0 1021    0    0   12]\n",
      " [   0    0    0    0  118    0    5]\n",
      " [   0    0    0    2    0   96   14]\n",
      " [   2    0    0    0    0    0 3219]]\n",
      "GradientBoosting :0.913710450623\n",
      "Confusion Matrix : Gradient Boosting\n",
      "[[1295    0    0    0    0    0    0]\n",
      " [   0   35    0    0    0    0    0]\n",
      " [   0    0  353    5    0    0   72]\n",
      " [   0    0    3 1029    1    0    0]\n",
      " [   0    0    0    0  121    0    2]\n",
      " [   0    0    0    0    0  111    1]\n",
      " [   0    0    1    0    0    0 3220]]\n",
      "KNN :0.888142102736\n",
      "Confusion Matrix : KNN\n",
      "[[1277    0    0    4    1    0   13]\n",
      " [   4   10    5    8    0    0    8]\n",
      " [   1    3  166   20    1    0  239]\n",
      " [   0    0    7 1013    1    5    7]\n",
      " [   0    0    0   20   88    0   15]\n",
      " [   0    0    3   64    1   34   10]\n",
      " [  24    0   29    5    0    0 3163]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV()\n",
    "lr.fit(X_train, y_train)\n",
    "cv_lr = min(cross_val_score(lr, X_train, y_train, cv=3))\n",
    "print(\"Logistic Regression :\"+str(cv_lr))\n",
    "print(\"Confusion Matrix : Logistic Reegression\")\n",
    "print(confusion_matrix(y_train, lr.predict(X_train)))\n",
    "\n",
    "svm = SVC(C=8, kernel='rbf') # Parameters chosen by GridSearh\n",
    "svm.fit(X_train, y_train)\n",
    "cv_svm = min(cross_val_score(svm, X_train, y_train, cv=3))\n",
    "print(\"SVM :\"+str(cv_svm))\n",
    "print(\"Confusion Matrix : SVM\")\n",
    "print(confusion_matrix(y_train, svm.predict(X_train)))\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "cv_gb = min(cross_val_score(gb, X_train, y_train, cv=3))\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"GradientBoosting :\"+str(cv_gb))\n",
    "print(\"Confusion Matrix : Gradient Boosting\")\n",
    "print(confusion_matrix(y_train, gb.predict(X_train)))\n",
    "\n",
    "knn = KNeighborsClassifier() # Parameters chosen by GridSearh\n",
    "knn.fit(X_train, y_train)\n",
    "cv_knn = min(cross_val_score(knn, X_train, y_train, cv=3))\n",
    "print(\"KNN :\"+str(cv_knn))\n",
    "print(\"Confusion Matrix : KNN\")\n",
    "print(confusion_matrix(y_train, knn.predict(X_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Discriminant Analysis\n",
    "**  LDA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_da_lr(projected, y):\n",
    "    \"\"\"Predict the output from the DA method\"\"\"\n",
    "    lr = LogisticRegressionCV()\n",
    "    lr.fit(projected, y)\n",
    "    y_pred = lr.predict(projected)\n",
    "    return y_pred\n",
    "def predict_da_svm(projected, y):\n",
    "    \"\"\"Predict the output from the DA method\"\"\"\n",
    "    svm = SVC(C = 8, kernel='rbf')\n",
    "    svm.fit(projected, y)\n",
    "    y_pred = svm.predict(projected)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lda(X,y, cla = None):\n",
    "    if cla==None:\n",
    "        cla = np.unique(y)\n",
    "        ix = np.in1d(y, cla)\n",
    "    else :\n",
    "        ix = np.in1d(y, cla)\n",
    "        y = y[ix]\n",
    "        X = X[ix]\n",
    "        \n",
    "    N_features = X.shape[1]\n",
    "    Sw = np.zeros((N_features, N_features)) # Within Matrix\n",
    "    Sb = np.zeros((N_features, N_features)) # Between Class Matrix\n",
    "    u = np.mean(X, axis=0)\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        if cl in cla:  \n",
    "            index = np.where(y==cl)\n",
    "            Sw += np.cov(X[index].T)\n",
    "            Ni = len(index[0])\n",
    "            mn = np.mean(X[index], axis=0)\n",
    "            x = mn - u\n",
    "            x = x[:, None]\n",
    "            Sb += Ni*np.dot(x,x.T)\n",
    "    \n",
    "        \n",
    "    # Projection Matrix Theta\n",
    "    Proj_dim = np.unique(y).shape[0]-1\n",
    "    w,v =  np.linalg.eig(np.dot(np.linalg.inv(Sw),Sb))\n",
    "    Theta = np.real(v[:,0:Proj_dim])\n",
    "    projected = np.dot(Theta.T, X.T).T # Projected data\n",
    "    return projected, ix\n",
    "Y_lda, ix_lda = lda(X_train_da,y_train, cla=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA + Logistic Regression :0.884947267498\n",
      "Confusion Matrix : LDA + LR\n",
      "[[1267    0    0    3    0    0   25]\n",
      " [   0    0    0    1    0    0   34]\n",
      " [   0    0    0   18    5    1  406]\n",
      " [   0    0    0  998    3    7   25]\n",
      " [   0    0    0    1  104    1   17]\n",
      " [   0    0    0   33    1   61   17]\n",
      " [ 117    0    0    4    1    1 3098]]\n",
      "LDA + SVM :0.901246404602\n",
      "Confusion Matrix : LDA + SVM\n",
      "[[1269    4    0    1    0    0   21]\n",
      " [   0   25    0    0    0    0   10]\n",
      " [   0    1    5   13    3    1  407]\n",
      " [   0    0    0  997    3   11   22]\n",
      " [   0    0    0    4  108    0   11]\n",
      " [   0    0    0   15    1   81   15]\n",
      " [   5    1    1    3    1    1 3209]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV()\n",
    "lr.fit(Y_lda, y_train[ix_lda])\n",
    "cv_lda_lr = min(cross_val_score(lr, Y_lda, y_train[ix_lda], cv=3))\n",
    "print(\"LDA + Logistic Regression :\"+str(cv_lda_lr))\n",
    "print(\"Confusion Matrix : LDA + LR\")\n",
    "print(confusion_matrix(y_train, lr.predict(Y_lda)))\n",
    "\n",
    "\n",
    "svm = SVC(C = 10, kernel='rbf')\n",
    "svm.fit(Y_lda, y_train[ix_lda])\n",
    "cv_lda_svm = min(cross_val_score(svm, Y_lda, y_train[ix_lda], cv=3))\n",
    "print(\"LDA + SVM :\"+str(cv_lda_svm))\n",
    "print(\"Confusion Matrix : LDA + SVM\")\n",
    "print(confusion_matrix(y_train[ix_lda], svm.predict(Y_lda)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** KDA ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def w_matrix(x1,x2):\n",
    "    \"\"\" Matrix of i and j : 1/mk if i==j, 0 else\"\"\"\n",
    "    n = len(x1)\n",
    "    M = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        mk =  len(np.where(y==y[i])[0])\n",
    "        M[i,:] = np.equal(x1[i],x2).astype(int)*(1./mk)\n",
    "    return M\n",
    "\n",
    "def kda(X, y, cla = None):\n",
    "    if cla==None:\n",
    "        cla = np.unique(y)\n",
    "        ix = np.in1d(y, cla)\n",
    "    else :\n",
    "        ix = np.in1d(y, cla)\n",
    "        y = y[ix]\n",
    "        X = X[ix]\n",
    "        \n",
    "    K=rbf_kernel(X,X)\n",
    "    n = K.shape[0]\n",
    "    W = w_matrix(y,y)\n",
    "    # Within-class scatter matrix\n",
    "    Sw = np.dot(K,K)\n",
    "    # Between-class scatter matrix\n",
    "    Sb = np.dot(K,np.dot(W,K))\n",
    "    # Project Matrices\n",
    "    Proj_dim = np.unique(y).shape[0]-1\n",
    "    w,v =  np.linalg.eig(np.dot(np.linalg.inv(Sw),Sb))\n",
    "    Alpha = np.real(v[:,0:Proj_dim])\n",
    "    projected = np.dot(Alpha.T, K).T\n",
    "    return projected, ix  \n",
    "\n",
    "Y_kda, ix_kda = kda(X_train_da,y_train, cla=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDA + Logistic Regression :0.925961538462\n",
      "Confusion Matrix : KDA + LR\n",
      "[[1295    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0   35]\n",
      " [   0    0  430    0    0    0    0]\n",
      " [   0    0    0 1033    0    0    0]\n",
      " [   0    0    0    0  123    0    0]\n",
      " [   0    0    0    0    0  112    0]\n",
      " [   0    0    0    0    0    0 3221]]\n",
      "KDA + SVM :0.994239078253\n",
      "Confusion Matrix : KDA + SVM\n",
      "[[1295    0    0    0    0    0    0]\n",
      " [  35    0    0    0    0    0    0]\n",
      " [   0    0  430    0    0    0    0]\n",
      " [   0    0    0 1033    0    0    0]\n",
      " [   0    0    0    0  123    0    0]\n",
      " [   0    0    0    0    0  112    0]\n",
      " [   0    0    0    0    0    0 3221]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV()\n",
    "lr.fit(Y_kda, y_train[ix_kda])\n",
    "cv_kda_lr = min(cross_val_score(lr, Y_kda, y_train[ix_kda], cv=3))\n",
    "print(\"KDA + Logistic Regression :\"+str(cv_kda_lr))\n",
    "print(\"Confusion Matrix : KDA + LR\")\n",
    "print(confusion_matrix(y_train[ix_kda], lr.predict(Y_kda)))\n",
    "svm = SVC(C = 1500, kernel='linear')\n",
    "svm.fit(Y_kda, y_train[ix_kda])\n",
    "cv_kda_svm = min(cross_val_score(svm, Y_kda, y_train[ix_kda], cv=3))\n",
    "print(\"KDA + SVM :\"+str(cv_kda_svm))\n",
    "print(\"Confusion Matrix : KDA + SVM\")\n",
    "print(confusion_matrix(y_train[ix_kda], svm.predict(Y_kda)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
